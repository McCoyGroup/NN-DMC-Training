import pickle
import numpy as np
import matplotlib.pyplot as plt
from pyvibdmc.analysis import *
from pyvibdmc.simulation_utilities import *
from pyvibdmc.simulation_utilities.tensorflow_descriptors.cupy_distance import DistIt

import tensorflow as tf
from tensorflow.keras.layers import Dense, InputLayer
import tensorflow.keras.backend as K
from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession

import cupy as cp

tf.keras.backend.set_floatx('float64')
config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)

#Load in training and validation set - Load in test data later
train = np.load("train_xy.npz")
train_x = train['train_x']
train_y = train['train_y']
val = np.load("val_xy.npz")
val_x = val['val_x']
val_y = val['val_y']

#Transform your data to the appropriate descriptor
eq_geom = np.load("/gscratch/ilahie/rjdiri/dmc/trimer_training/udu_bohr.npy")
eq_geom = Constants.convert(eq_geom,'angstroms',to_AU=False)
eq_geom = np.array([eq_geom,eq_geom])
dist = DistIt(zs=[8,1,1]*3, sort_mat=False)

req = dist.run(cp.array(eq_geom))[0]
print(req)

train_r = dist.run(cp.array(train_x))
train_spf = tf.convert_to_tensor(cp.asnumpy((train_r - req) / train_r))

val_r = dist.run(cp.array(val_x))
val_spf = tf.convert_to_tensor(cp.asnumpy((val_r - req) / val_r))

# Includes transforming energy !
train_y = np.log10(train_y/1000+1)
val_y = np.log10(val_y/1000+1)

print('~~~~~~~~SHAPES~~~~~~~~~')
print(train_spf.shape)
print(train_y.shape)
print(val_spf.shape)
print(val_y.shape)
print('~~~~~~~~SHAPES~~~~~~~~~')

#Define mae metric for monitoring training+validation while training
def mae(y_true, y_pred):
    return K.mean(K.abs((10**(y_true-1)*1000)-(10**(y_pred-1)*1000)))
   
print('input layer shape')
print(len(train_spf[0]))
print('input layer shape')
# NN structure
model = tf.keras.Sequential(
[
    InputLayer(input_shape=(len(train_spf[0]),)),
    Dense(210, activation=tf.nn.swish),
    Dense(210, activation=tf.nn.swish),
    Dense(210, activation=tf.nn.swish),
    Dense(1, activation='relu')
]
)

# Callbacks and Optimizer -> compile model
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='mae', 
                                                 factor=0.5,
                                                 patience=5,
                                                 min_delta=0.5,
                                                 min_lr=0.001/1024)

model_chkpt = tf.keras.callbacks.ModelCheckpoint('trimer_train.{epoch:02d}-{mae:.2f}.hdf5', 
                                                 monitor='mae',
                                                 verbose=1, 
                                                 save_best_only=False,
                                                 save_weights_only=True,
                                                 save_freq='epoch')

optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001/4)
# model.load_weights('...')
model.compile(optimizer=optimizer,
                 loss=tf.keras.losses.MeanSquaredError(),
                 metrics=[mae])
				 
data = model.fit(x=train_spf,
                 y=train_y,
                 epochs=100,
                 validation_data=(val_spf,val_y),
                 batch_size=32,
                 validation_batch_size=32,
                 shuffle=True,
                 callbacks = [reduce_lr,model_chkpt]
                )
with open('history_1.pickle', 'wb') as handle:
    pickle.dump(data.history, handle, protocol=4)  
tf.keras.models.save_model(model,'trimer_model')
